{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from math import isnan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from typing import Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/raw_in/\"\n",
    "file_name = \"Risques 2/data_set_challenge.csv\"\n",
    "mapping_name = \"Risques 2/final_mapping_candidat.csv\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, file_name), index_col=0)\n",
    "mapping = pd.read_csv(os.path.join(data_dir, mapping_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The data frame consists of {df.shape[0]} entries over {df.shape[1]} series\")\n",
    "print(\"-\" * 55)\n",
    "print(mapping.Type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD TO PREPROCESSING FUNCTION\n",
    "\n",
    "\n",
    "# --- step 1: identify the different types of series\n",
    "df.columns = [str(typ) + \"_\" + str(col) for col, typ in zip(df.columns, mapping.Type)]\n",
    "# --- Share prices & Stock indexes\n",
    "df_stock = df.loc[:, df.columns.str.contains(\"STOCK\")]\n",
    "# --- OAT bond (obligation assimilables au trÃ©sor) prices\n",
    "df_bond = df.loc[:, df.columns.str.contains(\"BOND\")]\n",
    "# --- Exchange rate\n",
    "df_xchang = df.loc[:, df.columns.str.contains(\"FXRATE\")]\n",
    "# --- Interests rate\n",
    "df_yieldc = df.loc[:, df.columns.str.contains(\"YIELD_CURVE\")]\n",
    "# --- Commodity price\n",
    "df_commod = df.loc[:, df.columns.str.contains(\"COMMO_CURVE_FO\")]\n",
    "# --- CDS Spread\n",
    "df_cdsb = df.loc[:, df.columns.str.contains(\"CDS_BASKET_ZC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data_frame: pd.DataFrame, category: str, show_corr: bool) -> None:\n",
    "    data_frame = data_frame.loc[:, data_frame.columns.str.contains(category)]\n",
    "\n",
    "    if show_corr:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 15))\n",
    "        # --- display missing values\n",
    "        sns.heatmap(data_frame.isnull(),\n",
    "                    cbar=False,\n",
    "                    ax=ax[0])\n",
    "        # --- display correlation heatmap\n",
    "        corr = data_frame.corr()\n",
    "        sns.heatmap(corr,\n",
    "                    mask = np.triu(np.ones_like(corr, dtype=bool)),\n",
    "                    ax = ax[1],\n",
    "                    center=0)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 15))\n",
    "        # --- display missing values\n",
    "        sns.heatmap(data_frame.isnull(),\n",
    "                    cbar=False,\n",
    "                    ax=ax[1])\n",
    "    return None\n",
    "\n",
    "plot_data(data_frame=df, category='BOND', show_corr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing with correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are missing value at timestamp **t** for time serie **i**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We look at the **growth rate** between time **t-1** and **t** for all available time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To **weight** the actual relevance of the obtained growth rate for each time serie, we use the overall correlation with the original time serie **i**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We then infer the growth rate of serie **i** at time **t**: <br> <br>\n",
    "$ ImputedGrowthRate_i (t) = \\frac{\\sum_{j \\neq i} GrowthRate_j (t)  *  Corr(i,j)} {\\sum_{j \\neq i} Corr(i,j)}$ \n",
    "<br><br> where $Corr(i,j)$ is the correlation of **returns** (not absolute values) of series i and j across all period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- And thus the value of serie **i** at time **t**: <br> <br>\n",
    "$  TimeSerie_i(t) = ImputedGrowthRate_i (t) * TimeSerie_i(t-1)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, instead of using all correlations raw, we can pre-process them before using them as weights (cf. below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing growth rate and correlation matrices from original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth_rates_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param df: the original data frame, with missing values\n",
    "    :return: observed growth rates on the original data frame for each period (nan when infinite or unavailable)\n",
    "    \"\"\"\n",
    "    growth_rates = df.pct_change(fill_method=None)\n",
    "    growth_rates.replace([np.inf, -np.inf], np.nan, inplace=True)  # Change inf values to na, will be dropped later\n",
    "    return growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param df: the original data frame, with missing values\n",
    "    :return: a correlation matrix of the original data frame, based on pct changes each period (not absolute values)\n",
    "    \"\"\"\n",
    "    df_returns = get_growth_rates_df(df)\n",
    "    corr_df = df_returns.corr()\n",
    "    # Set to zero when correlation cannot be computed (ex. constant time series)\n",
    "    corr_df = corr_df.fillna(0)\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various 'activation' functions for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_below_threshold(num: float, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    :param num: a correlation float\n",
    "    :param threshold: threshold under which correlations should be disregarded\n",
    "    :return: either the original correlation, or zero\n",
    "    \"\"\"\n",
    "    if abs(num) < threshold:\n",
    "        return 0\n",
    "\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECISION_EPSILON = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_distance_to_1(num: float) -> float:\n",
    "    \"\"\"\n",
    "    :param num: a correlation float\n",
    "    :return: a positive weight that tends to +inf as correlation approaches 1\n",
    "    \"\"\"\n",
    "    return 1 / (1 - num + PRECISION_EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_truncate_inverse_distance(num: float, threshold: float = 0.9) -> float:\n",
    "    \"\"\"\n",
    "    :param num: a correlation float\n",
    "    :param threshold: threshold under which correlations should be disregarded\n",
    "    :return: either a positive weight that tends to +inf as correlation approaches 1, or zero\n",
    "    \"\"\"\n",
    "    if abs(num) < threshold:\n",
    "        return 0\n",
    "\n",
    "    return num / (1 - num + PRECISION_EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f(f: Callable[[float], float]) -> None:\n",
    "    \"\"\"\n",
    "    Plot activation functions\n",
    "    \"\"\"\n",
    "    points = 10000  # Number of points\n",
    "    xmin, xmax = 0.01, 0.99\n",
    "    xlist = [float(xmax - xmin) *i / points for i in range(points+1)]\n",
    "    ylist = [f(x) for x in xlist]\n",
    "    plt.plot(xlist, ylist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f(truncate_below_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f(inverse_distance_to_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f(mixed_truncate_inverse_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_correlations(corr_df: pd.DataFrame, activation_f: Callable[[float], float]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Activate a correlation data frame column by column, value by value, with pandas parallelism\n",
    "    :param corr_df: a correlation matrix\n",
    "    :param activation_f: a correlation pre processing function\n",
    "    :return: a symmetric matrix of weights based on correlations\n",
    "    \"\"\"\n",
    "    return corr_df.apply(lambda corr_series: corr_series.apply(activation_f), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two highly correlated series (>0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name0 = \"BOND_0\"\n",
    "name1 = \"BOND_1\"\n",
    "plt.plot(df[name0], label=name0)\n",
    "plt.plot(df[name1], label=name1)\n",
    "plt.xticks([])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing missing values out of correlations and growth rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_day(timestamp_str: str, date_format: str = '%d/%m/%Y') -> str:\n",
    "    \"\"\"\n",
    "    Takes a date string in a particular format, returns the date string of the day before in the same format\n",
    "    \"\"\"\n",
    "    timestamp = pd.to_datetime(timestamp_str, format=date_format)\n",
    "    prev_day_timestamp = timestamp + timedelta(days=-1)\n",
    "    prev_day_timestamp_str = prev_day_timestamp.strftime(date_format)\n",
    "    return prev_day_timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_available_day(timestamp_str: str, available_days: pd.Index) -> str:\n",
    "    \"\"\"\n",
    "    Takes a current date string, returns the previous date string in an index of possible of date strings\n",
    "    :param timestamp_str: the current date string\n",
    "    :param available_days: the index of all date-strings with observations\n",
    "    :return: the previous date string observed in the list\n",
    "    \"\"\"\n",
    "    prev_timestamp_str = prev_day(timestamp_str)\n",
    "    while prev_timestamp_str not in available_days:\n",
    "        prev_timestamp_str = prev_day(prev_timestamp_str)\n",
    "    return prev_timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputed_value(time_series: pd.Series, timestamp_str: str, imputed_growth_rate: Union[float, None]) -> float:\n",
    "    \"\"\"\n",
    "    Returns an imputed value at a given time based on the last value and an imputed growth rate\n",
    "    \"\"\"\n",
    "    if imputed_growth_rate is None:\n",
    "        return np.nan\n",
    "\n",
    "    prev_timestamp_str = get_previous_available_day(timestamp_str, time_series.index)\n",
    "    prev_value = time_series[prev_timestamp_str]\n",
    "\n",
    "    # Multiply by imputed growth rate\n",
    "    imputed_value = prev_value * (1 + imputed_growth_rate)\n",
    "\n",
    "    return imputed_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputed_growth_rate(corr_series_activated: pd.Series, growth_rates: pd.Series) -> Union[float, None]:\n",
    "    \"\"\"\n",
    "    Returns an average of observed growth rates, weighted by pre processed correlations of the corresponding series\n",
    "    \"\"\"\n",
    "    # Retrieve indices where growth rate is available\n",
    "    not_nan_indices = np.where(np.logical_not(np.isnan(growth_rates)))[0]\n",
    "    # Compute average of growth rates weighted by 'activated' correlation\n",
    "    if np.sum(corr_series_activated[not_nan_indices]) == 0:\n",
    "        return None\n",
    "    imputed_growth_rate = np.average(growth_rates[not_nan_indices], weights=corr_series_activated[not_nan_indices])\n",
    "    return imputed_growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_time_series(df_time_series: pd.DataFrame, series_id: str,\n",
    "                        corr_df_activated: pd.DataFrame, growth_rates_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Impute missing value on a time series, using correlations and growth rates\n",
    "    \"\"\"\n",
    "    time_series_filled = pd.Series(index=df_time_series[series_id].index, name=series_id)\n",
    "    not_started = True\n",
    "    for timestamp_str, value in df_time_series[series_id].items():\n",
    "\n",
    "        if isnan(value):\n",
    "            if not_started:\n",
    "                # data not yet available for this time series\n",
    "                continue\n",
    "\n",
    "            corr_series_activated = corr_df_activated[series_id]\n",
    "            growth_rate_series = growth_rates_df.loc[timestamp_str]\n",
    "            imputed_growth_rate = get_imputed_growth_rate(corr_series_activated, growth_rate_series)\n",
    "            imputed_value = get_imputed_value(time_series_filled, timestamp_str, imputed_growth_rate)\n",
    "            time_series_filled[timestamp_str] = imputed_value\n",
    "\n",
    "        else:\n",
    "            if not_started:\n",
    "                not_started = False\n",
    "\n",
    "            time_series_filled[timestamp_str] = value\n",
    "\n",
    "    return time_series_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_data_frame(df_time_series: pd.DataFrame, corr_df_activated: pd.DataFrame,\n",
    "                       growth_rates_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Impute missing value on the data frame, using correlations and growth rates\n",
    "    \"\"\"\n",
    "\n",
    "    tqdm.pandas()  # show progress bar\n",
    "\n",
    "    df_time_series_filled = df_time_series.progress_apply(\n",
    "        lambda time_series: fill_in_time_series(df_time_series, time_series.name, corr_df_activated, growth_rates_df),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # Simply interpolate when correlation method fails to impute (ex. no series sufficiently correlated)\n",
    "    df_final = df_time_series_filled.interpolate(method='linear', limit=None, limit_direction='forward')\n",
    "\n",
    "    # Compute and display some metrics\n",
    "    num_accepted_nans = df_final.isna().sum().sum()\n",
    "    num_values = df_final.count().sum()\n",
    "    pct_originally_missing = (df_time_series.isna().sum().sum() - num_accepted_nans) / num_values\n",
    "    pct_missing_after_corr_method = (df_time_series_filled.isna().sum().sum() - num_accepted_nans) / num_values\n",
    "    print(f\"Originally missing: {round(pct_originally_missing*100,1)}%\")\n",
    "    print(f\"Still missing after correlation imputation method: {round(pct_missing_after_corr_method*100,1)}%\")\n",
    "    print(f\"Missing after final interpolation: 0.0%\")\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df_with_correlations(df: pd.DataFrame, corr_activation_f: Callable[[float], float]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    :param df: the original data frame, with missing values\n",
    "    :param corr_activation_f: a correlation pre processing function to compute weights\n",
    "    :return: the original data frame with imputed missing values, using correlations and growth rates\n",
    "    \"\"\"\n",
    "    print(\"Performing preliminary calculations...\")\n",
    "    growth_rates_df = get_growth_rates_df(df)\n",
    "    corr_df = get_correlations_df(df)\n",
    "    corr_df_activated = activate_correlations(corr_df, corr_activation_f)\n",
    "\n",
    "    print(\"Imputing missing values...\")\n",
    "    df_imputed = fill_in_data_frame(df, corr_df_activated, growth_rates_df)\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = impute_df_with_correlations(df, mixed_truncate_inverse_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(dataframe=df_imputed, category='BOND', show_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
